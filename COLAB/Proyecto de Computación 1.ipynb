{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7752,"status":"ok","timestamp":1700305596783,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"},"user_tz":-60},"id":"kILQFi6Jw9A0","outputId":"e519dae6-4429-40fe-92f3-6c5413fd21ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.9.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n","Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (23.9.7)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.23.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.11.3)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n"]}],"source":["!pip install scikit-optimize"]},{"cell_type":"markdown","metadata":{"id":"Fl2_I4t7JuFG"},"source":["# New Section"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RfOvqC0TGkxj","executionInfo":{"status":"ok","timestamp":1700305598991,"user_tz":-60,"elapsed":2211,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"outputId":"66f4d153-a944-4476-bce7-321028aa3fb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pz4v-MZ8jbUH"},"outputs":[],"source":["# import required libraries\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBW8t4_SjdxX"},"outputs":[],"source":["# read dataset function\n","def read_dataset(inFile):\n","    print(\"\\nReading:\", inFile)\n","    data =  pd.read_csv(inFile, sep='\\t')\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CF17EiI7jvI-"},"outputs":[],"source":["# data paths and config\n","inTrain = '/content/drive/MyDrive/dataset.csv'\n","\n","max_instances_per_class = 1500\n","max_features = 20000 # maximum number of features extracted for our instances\n","random_seed = 777 # set random seed for reproducibility\n","id2label = {0: \"HUMANO\", 1: \"IA\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YD-29tskP93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700305598992,"user_tz":-60,"elapsed":19,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"outputId":"746ade73-329c-4539-aee2-22702b826e89"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Reading: /content/drive/MyDrive/dataset.csv\n"]}],"source":["# read dataset\n","train_df = read_dataset(inTrain)\n","train_df, test_df = train_test_split(train_df, test_size=0.2, stratify=train_df['Label'], random_state=random_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrjefNsJkJaP"},"outputs":[],"source":["from itertools import count\n","# downsample training data to train faster\n","train_df = train_df.groupby(\"Label\").sample(n=max_instances_per_class, random_state=random_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33j_uuSjBS17"},"outputs":[],"source":["#Establecemos el número de instancias presentes\n","instancias_humanas = len(train_df[train_df['Label'] == 'HUMANO'])\n","instancias_ia =  len(train_df[train_df['Label'] == 'IA'])\n","instancias_dataset = len(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzbprNdK6_nb"},"outputs":[],"source":["#Sumamos las instancias y realizamos la longitud media\n","suma_longitudes_humanos = train_df[train_df['Label'] == 'HUMANO']['Text'].apply(len).sum()\n","longitud_media_humanos = suma_longitudes_humanos / instancias_humanas\n","\n","suma_longitudes_generados = train_df[train_df['Label'] == 'IA']['Text'].apply(len).sum()\n","longitud_media_generado = suma_longitudes_generados / instancias_ia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuU16cOQ7QQx","executionInfo":{"status":"ok","timestamp":1700305599260,"user_tz":-60,"elapsed":11,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9517eb5a-6471-4e62-ae6f-e50d1e4901fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de instancias en el dataset:\t\t\t\t 3000\n","Número de instancias humanas:\t\t\t\t\t 1500\n","Número de instancias generadas:\t\t\t\t\t 1500\n","Longitud media en caracteres de las instancias humanas:\t\t 489.0926666666667\n","Longitud media en caracteres de las instancias generadas:\t 1308.508\n"]}],"source":["#Imprimimos la Tabla de Estadísticas\n","print('Número de instancias en el dataset:\\t\\t\\t\\t', instancias_dataset)\n","print('Número de instancias humanas:\\t\\t\\t\\t\\t', instancias_humanas)\n","print('Número de instancias generadas:\\t\\t\\t\\t\\t', instancias_ia)\n","print('Longitud media en caracteres de las instancias humanas:\\t\\t', longitud_media_humanos)\n","print('Longitud media en caracteres de las instancias generadas:\\t', longitud_media_generado)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHdZ48gBlJB8"},"outputs":[],"source":["# vectorize data: extract features from our data (from text to numeric vectors)\n","vectorizer = TfidfVectorizer(max_features=max_features, stop_words=\"english\", ngram_range=(1,1))\n","X_train = vectorizer.fit_transform(train_df[\"Text\"])\n","X_test = vectorizer.transform(test_df[\"Text\"])\n","#print({k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1], reverse=True)})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2jZYOPLmFcW"},"outputs":[],"source":["# vectorize labels : from text to numeric vectors\n","le = LabelEncoder()\n","Y_train = le.fit_transform(train_df[\"Label\"])\n","Y_test = le.transform(test_df[\"Label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YlbB5Thk8OG"},"outputs":[],"source":["# create model\n","model = ExtraTreesClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvkEVOJylFQO","executionInfo":{"status":"ok","timestamp":1700305604560,"user_tz":-60,"elapsed":4979,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"colab":{"base_uri":"https://localhost:8080/","height":75},"outputId":"98dd5b97-8b69-4751-9e14-4f0d0cf8d98f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ExtraTreesClassifier()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":28}],"source":["# train model\n","model.fit(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igOJBWhl8-tg","executionInfo":{"status":"ok","timestamp":1700305860587,"user_tz":-60,"elapsed":256,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"466a5acd-a646-4f10-a5a6-12ae002ecead"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de instancias en el training:\t\t 3000\n","Número de instancias en el test:\t\t 860\n","Número de instancias humanas en el training:\t 1500\n","Número de instancias generadas en el training:\t 1500\n","Número de instancias generadas en el test:\t 466\n","Número de instancias humanas en el test:\t 394\n"]}],"source":["#Imprimimos Tabla de Estadísticas\n","print('Número de instancias en el training:\\t\\t',len(train_df))\n","print('Número de instancias en el test:\\t\\t',len(test_df))\n","print('Número de instancias humanas en el training:\\t',len(train_df[train_df['Label'] == 'HUMANO']))\n","print('Número de instancias generadas en el training:\\t',len(train_df[train_df['Label'] == 'IA']))\n","print('Número de instancias generadas en el test:\\t',len(test_df[test_df['Label'] == 'IA']))\n","print('Número de instancias humanas en el test:\\t',len(test_df[test_df['Label'] == 'HUMANO']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNEQoloammRN"},"outputs":[],"source":["# get test predictions\n","predictions = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SekZcVW0nBlV","executionInfo":{"status":"ok","timestamp":1700305604932,"user_tz":-60,"elapsed":17,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b0c7c30d-254c-4ac2-ddc7-bd1476833330"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","      HUMANO       0.86      0.91      0.88       394\n","          IA       0.92      0.87      0.90       466\n","\n","    accuracy                           0.89       860\n","   macro avg       0.89      0.89      0.89       860\n","weighted avg       0.89      0.89      0.89       860\n","\n"]}],"source":["# evaluate predictions\n","target_names = [label for idx, label in id2label.items()]\n","print(classification_report(Y_test, predictions, target_names=target_names))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTuUJlLVutwR","executionInfo":{"status":"ok","timestamp":1700305604932,"user_tz":-60,"elapsed":16,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd961b8d-74c4-412b-cf9c-292287b33c14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classification label: HUMANO\n"]}],"source":["# classify your own text\n","custom_texts = [\"I'm ChatGPT, your virtual assistant, and I'm generating texts\"]\n","X_custom = vectorizer.transform(custom_texts)\n","preds = model.predict(X_custom)\n","print(\"Classification label:\", target_names[preds[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQ7sMUu_td04","executionInfo":{"status":"ok","timestamp":1700305803391,"user_tz":-60,"elapsed":198468,"user":{"displayName":"Mauro Moltrasio","userId":"04557905840670213428"}},"outputId":"832138d2-f586-4022-c859-2b9c84675350"},"outputs":[{"output_type":"stream","name":"stdout","text":["Calculando el Mejor Modelo...\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n",".\n","\n","__________________________________________________\n","\n","          --- TOP 5 MEJORES MODELOS ---           \n","__________________________________________________\n","\n"," TOP  |          MODELO           |   PUNTUACIÓN   \n","__________________________________________________\n","\n","  1   |   ExtraTreesClassifier    |   0.891564    | <- Modelo Recomendado\n","  2   |       MLPClassifier       |   0.878014    | \n","  3   |      RidgeClassifier      |   0.877541    | \n","  4   |     RidgeClassifierCV     |   0.877541    | \n","  5   |  CalibratedClassifierCV   |   0.877441    | \n"]}],"source":["import warnings\n","from sklearn.exceptions import ConvergenceWarning\n","from sklearn.utils import all_estimators\n","from sklearn.base import ClassifierMixin\n","from sklearn.metrics import f1_score\n","\n","# Filtrar todas las advertencias de convergencia\n","warnings.filterwarnings('ignore', category=ConvergenceWarning)\n","\n","best_score = float('-inf')\n","best_model = None\n","top_modelos = []\n","\n","print('Calculando el Mejor Modelo...')\n","for name, ClassifierClass in all_estimators(type_filter='classifier'):\n","      if issubclass(ClassifierClass, ClassifierMixin) and hasattr(ClassifierClass, 'fit'):\n","        try:\n","            regressor = ClassifierClass()\n","            regressor.fit(X_train, Y_train)\n","            y_pred = regressor.predict(X_test)\n","            score = f1_score(Y_test, y_pred, average=\"macro\")\n","            top_modelos.append((score, name, regressor))\n","            if score > best_score:\n","                best_score = score\n","                best_model = regressor\n","            #print(f\"Modelo : {name} | Macro F1: {score}\")\n","        except Exception as e:\n","          print('.')\n","\n","#Ordenamos los modelos de mayor a menor\n","top_modelos.sort(reverse=True, key=lambda x: x[0])\n","\n","#Establecemos el top de mejores modelos\n","top_five = top_modelos[:5]\n","\n","#Establecemos el formato para la tabla\n","print('\\n{:_<50}'.format(\"\"))\n","print(\"\\n{:^50}\".format(\"--- TOP 5 MEJORES MODELOS ---\"))\n","print('{:_<50}'.format(\"\"))\n","print(\"\\n{:^5} | {:^25} | {:^15}\".format(\"TOP\", \"MODELO\", \"PUNTUACIÓN\"))\n","print('{:_<50}\\n'.format(\"\"))\n","\n","#Imprimimos el top 5 modelos\n","for i, (score, name, model) in enumerate(top_five, start=1):\n","  recommended = \"<- Modelo Recomendado\" if model == best_model else \"\"\n","  print(\"{:^5} | {:^25} | {:^13.6f} | {}\".format(i, name, score, recommended))"]}],"metadata":{"colab":{"provenance":[{"file_id":"18U3iXGJrw5X0LQLrglOZgdtNEin6MQoT","timestamp":1700390949818},{"file_id":"1mohjT96IuqC79ly8N1mV0yP-CgYL2l_R","timestamp":1700071358745}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}